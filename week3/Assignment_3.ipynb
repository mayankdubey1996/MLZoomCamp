{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6198dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import log2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6701bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06adf969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3accdabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading csv\n",
    "cols = [\"latitude\",\"longitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\n",
    "       \"households\",\"median_income\",\"median_house_value\",\"ocean_proximity\"]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d73933e",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "- Select only the features from above and fill in the missing values with 0.\n",
    "- Create a new column `rooms_per_household` by dividing the column `total_rooms` by the column households from dataframe.\n",
    "- Create a new column `bedrooms_per_room` by dividing the column `total_bedrooms` by the column total_rooms from dataframe.\n",
    "- Create a new column `population_per_household` by dividing the column population by the column households from dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfbd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "#only total_bedrooms has 207 nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b80a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the features from above and fill in the missing values with 0.\n",
    "df[\"total_bedrooms\"] = df[\"total_bedrooms\"].fillna(0)\n",
    "\n",
    "# Create a new column rooms_per_household by dividing the column total_rooms by the column households from dataframe.\n",
    "df[\"rooms_per_household\"] = df[\"total_rooms\"]/df[\"households\"]\n",
    "\n",
    "# Create a new column bedrooms_per_room by dividing the column total_bedrooms by the column total_rooms from dataframe.\n",
    "df[\"bedrooms_per_room\"] = df[\"total_bedrooms\"]/df[\"total_rooms\"]\n",
    "\n",
    "# Create a new column population_per_household by dividing the column population by the column households from dataframe.\n",
    "df[\"population_per_household\"] = df[\"population\"]/df[\"households\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28eccb3",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "__What is the most frequent observation (mode) for the column ocean_proximity?__\n",
    "\n",
    "Options:\n",
    "\n",
    "- `NEAR BAY`\n",
    "- `<1H OCEAN`\n",
    "- `INLAND`\n",
    "- `NEAR OCEAN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470865f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ocean_proximity\"].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d91abc",
   "metadata": {},
   "source": [
    "__answer: `<1H OCEAN`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f830fb",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "- Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "- Use Scikit-Learn for that (the `train_test_split` function) and set the seed to 42.\n",
    "- Make sure that the target value (`median_house_value`) is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3b3254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11da8194",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols  = [\"latitude\",\"longitude\",\"housing_median_age\",\"total_rooms\",\"total_bedrooms\",\"population\",\n",
    "           \"households\",\"median_income\",\"ocean_proximity\"]\n",
    "y_col   = \"median_house_value\"\n",
    "\n",
    "X_train = df_train[X_cols]\n",
    "X_val   = df_val[X_cols]\n",
    "X_test  = df_test[X_cols]\n",
    "\n",
    "y_train = df_train[y_col] \n",
    "y_val   = df_val[y_col]\n",
    "y_test  = df_test[y_col]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd93d806",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "- Create the correlation matrix for the numerical features of your train dataset.\n",
    "         In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
    "- What are the two features that have the biggest correlation in this dataset?\n",
    "\n",
    "Options:\n",
    "\n",
    "- `total_bedrooms` and `households`\n",
    "- `total_bedrooms` and `total_rooms`\n",
    "- `population` and `households`\n",
    "- `population_per_household` and `total_rooms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9a7223",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(7, 7))\n",
    "sns.heatmap(X_train.corr(), annot = True, fmt= '.2f', cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be74875",
   "metadata": {},
   "source": [
    "__answer: `total_bedrooms` and `households`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0d9756",
   "metadata": {},
   "source": [
    "## Make median_house_value binary\n",
    "- We need to turn the `median_house_value` variable from numeric into binary.\n",
    "- Let's create a variable `above_average` which is 1 if the `median_house_value` is above its mean value and 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaddd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = y_train.mean()\n",
    "above_average = np.where(y_train>mu,0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307bd531",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "- Calculate the mutual information score with the (binarized) price for the categorical variable that we have. Use the training set only.\n",
    "- What is the value of mutual information?\n",
    "- Round it to 2 decimal digits using round(score, 2)\n",
    "\n",
    "__Options:__\n",
    "\n",
    "- __`0.263`__\n",
    "- __`0.00001`__\n",
    "- __`0.101`__\n",
    "- __`0.15555`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7a2f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mi(series):\n",
    "    return mutual_info_score(series, above_average)\n",
    "\n",
    "df_mi = df_train[cat].apply(calculate_mi)\n",
    "round(df_mi,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d822d9",
   "metadata": {},
   "source": [
    "__answer__: __`0.101`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc576b8b",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "- Now let's train a logistic regression\n",
    "- Remember that we have one categorical variable `ocean_proximity` in the data. Include it using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "        To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "        \n",
    "        model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "__Options:__\n",
    "    \n",
    "- __`0.60`__\n",
    "- __`0.72`__\n",
    "- __`0.84`__\n",
    "- __`0.95`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ceaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE HOT ENCODING \n",
    "X_train = pd.get_dummies(X_train)\n",
    "X_val  = pd.get_dummies(X_val)\n",
    "X_test = pd.get_dummies(X_test)\n",
    "\n",
    "# fit and transform y variable train, val and test\n",
    "\n",
    "#fit\n",
    "mu = y_train.mean()\n",
    "\n",
    "#transform\n",
    "oh_y_train = np.where(y_train>mu,0,1)\n",
    "\n",
    "oh_y_val   = np.where(y_val>mu,0,1)\n",
    "\n",
    "oh_y_test  = np.where(y_test>mu,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc1f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train,oh_y_train)\n",
    "y_pred_val = model.predict(X_val)\n",
    "accuracy = round(accuracy_score(oh_y_val, y_pred_val),2)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a217c5ec",
   "metadata": {},
   "source": [
    "__answer:__ __`Accuracy = 0.84`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52fdaff",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "- Let's find the least useful feature using the feature elimination technique.\n",
    "\n",
    "\n",
    "- Train a model with all these features (using the same parameters as in Q4).\n",
    "\n",
    "\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "\n",
    "\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "\n",
    "- Which of following feature has the smallest difference?\n",
    "    - `total_rooms`\n",
    "    - `total_bedrooms`\n",
    "    - `population`\n",
    "    - `households`\n",
    "    \n",
    "__note:__ the difference doesn't have to be positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab1ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X_train, X_val, drop_col):\n",
    "    XX_train = X_train.copy()\n",
    "    XX_val   = X_val.copy()\n",
    "    \n",
    "    XX_train = XX_train.drop(drop_col,axis=1)\n",
    "    XX_val   = XX_val.drop(drop_col,axis=1)\n",
    "    return XX_train, XX_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"total_rooms\",\"total_bedrooms\",\"population\",\"households\"]\n",
    "for col in columns:\n",
    "    XX_train, XX_val = get_data(X_train,X_val,col)\n",
    "    model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(XX_train,oh_y_train)\n",
    "    y_pred_val = model.predict(XX_val)\n",
    "    accuracy = round(accuracy_score(oh_y_val, y_pred_val),3)\n",
    "    print(\"Accuracy when \", col,\"is dropped:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d5d6d",
   "metadata": {},
   "source": [
    "__answer__: __`total_rooms`__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade9e7a",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "- For this question, we'll see how to use a linear regression model from Scikit-Learn\n",
    "\n",
    "\n",
    "- We'll need to use the original column `median_house_value`. Apply the logarithmic transformation to this column.\n",
    "\n",
    "\n",
    "- Fit the Ridge regression model (`model = Ridge(alpha=a, solver=\"sag\", random_state=42)`) on the training data.\n",
    "\n",
    "\n",
    "- This model has a parameter `alpha`. Let's try the following values: `[0, 0.01, 0.1, 1, 10]`\n",
    "\n",
    "\n",
    "- Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits.\n",
    "\n",
    "\n",
    "If there are multiple options, select the smallest `alpha`.\n",
    "\n",
    "__Options:__\n",
    "\n",
    "- __`0`__\n",
    "- __`0.01`__\n",
    "- __`0.1`__\n",
    "- __`1`__\n",
    "- __`10`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a5bbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the logarithmic transformation to median_house_value column.\n",
    "y_train = np.log1p(y_train)\n",
    "y_val = np.log1p(y_val)\n",
    "y_test = np.log1p(y_test)\n",
    "\n",
    "alphas = [0, 0.01, 0.1, 1, 10]\n",
    "for a in alphas:\n",
    "    model = Ridge(alpha=a, solver=\"sag\", random_state=42)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_val, y_val_pred)),3)\n",
    "    print(\"RMSE when alpha = \",a, \"is, \", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9e0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
