{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29bef9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers,models,optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d3af9f",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Since we have a binary classification problem, what is the best loss function for us?\n",
    "\n",
    "- `binary crossentropy`\n",
    "\n",
    "- `focal loss`\n",
    "\n",
    "- `mean squared error`\n",
    "\n",
    "- `categorical crossentropy`\n",
    "\n",
    "Note: since we specify an activation for the output layer, we don't need to set `from_logits=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0aa53c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = \"data/train\"\n",
    "TEST_DIR = \"data/test\"\n",
    "datagen = ImageDataGenerator()\n",
    "train_generator = datagen.flow_from_directory(TRAIN_DIR, class_mode=\"binary\",target_size=(150,150))\n",
    "validation_generator = datagen.flow_from_directory(TEST_DIR, class_mode=\"binary\",target_size=(150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac8de0",
   "metadata": {},
   "source": [
    "### Model\n",
    "For this homework we will use Convolutional Neural Network (CNN). Like in the lectures, we'll use Keras.\n",
    "\n",
    "You need to develop the model with following structure:\n",
    "\n",
    "- The shape for input should be `(150, 150, 3`)\n",
    "\n",
    "- Next, create a convolutional layer (`Conv2D`):\n",
    "    \n",
    "    - Use 32 filters\n",
    "    \n",
    "    - Kernel size should be `(3, 3)` (that's the size of the filter)\n",
    "    \n",
    "    - Use `'relu'` as activation\n",
    "                                    \n",
    "- Reduce the size of the feature map with max pooling (`MaxPooling2D`)\n",
    "    - Set the pooling size to `(2, 2)`\n",
    "- Turn the multi-dimensional result into vectors using a `Flatten` layer\n",
    "- Next, add a `Dense` layer with 64 neurons and `'relu'` activation\n",
    "- Finally, create the `Dense` layer with 1 neuron - this will be the output\n",
    "    - The output layer should have an activation - use the appropriate activation for the binary classification case\n",
    "\n",
    "As optimizer use SGD with the following parameters:\n",
    "\n",
    "- `SGD(lr=0.002, momentum=0.8)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9491b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(units=64,activation='relu'))\n",
    "model.add(layers.Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer=optimizers.SGD(learning_rate=0.002, momentum=0.8),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6b903e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.fit(train_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cedd310",
   "metadata": {},
   "source": [
    "__ANSWER__: a) `binary crossentropy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7573e1",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "What's the total number of parameters of the model? You can use the `summary` method for that.\n",
    "\n",
    "- 9215873\n",
    "- 11215873\n",
    "- 14215873\n",
    "- 19215873"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b246133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 175232)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                11214912  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,215,873\n",
      "Trainable params: 11,215,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77636054",
   "metadata": {},
   "source": [
    "__ANSWER__: b) `11215873`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9e606",
   "metadata": {},
   "source": [
    "### Generators and Training\n",
    "\n",
    "For the next two questions, use the following data generator for both train and validation:\n",
    "\n",
    "```python\n",
    "ImageDataGenerator(rescale=1./255)\n",
    "```\n",
    "\n",
    "- We don't need to do any additional pre-processing for the images.\n",
    "\n",
    "- When reading the data from train/val directories, check the class_mode parameter. Which value should it be for a binary classification problem?\n",
    "\n",
    "- Use `batch_size=20`\n",
    "\n",
    "- Use `shuffle=True` for both training and validation\n",
    "\n",
    "For training use `.fit()` with the following params:\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad5a7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fde26397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1594 images belonging to 2 classes.\n",
      "Found 394 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_directory(TRAIN_DIR, class_mode=\"binary\",shuffle=True,target_size=(150,150))\n",
    "validation_generator = datagen.flow_from_directory(TEST_DIR, class_mode=\"binary\",shuffle=True,target_size=(150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5125f3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50/50 [==============================] - 22s 438ms/step - loss: 0.6320 - accuracy: 0.6267 - val_loss: 0.5552 - val_accuracy: 0.6726\n",
      "Epoch 2/10\n",
      "50/50 [==============================] - 11s 229ms/step - loss: 0.4739 - accuracy: 0.7955 - val_loss: 0.4592 - val_accuracy: 0.7944\n",
      "Epoch 3/10\n",
      "50/50 [==============================] - 12s 240ms/step - loss: 0.4086 - accuracy: 0.8331 - val_loss: 0.3804 - val_accuracy: 0.8503\n",
      "Epoch 4/10\n",
      "50/50 [==============================] - 12s 232ms/step - loss: 0.3607 - accuracy: 0.8576 - val_loss: 0.3628 - val_accuracy: 0.8528\n",
      "Epoch 5/10\n",
      "50/50 [==============================] - 14s 271ms/step - loss: 0.3258 - accuracy: 0.8701 - val_loss: 0.3287 - val_accuracy: 0.8655\n",
      "Epoch 6/10\n",
      "50/50 [==============================] - 12s 239ms/step - loss: 0.2996 - accuracy: 0.8846 - val_loss: 0.3196 - val_accuracy: 0.8858\n",
      "Epoch 7/10\n",
      " 2/50 [>.............................] - ETA: 11s - loss: 0.2686 - accuracy: 0.9062"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cc70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3114306d",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "- 0.40\n",
    "- 0.60\n",
    "- 0.90\n",
    "- 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36155fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.median(history.history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986bae6b",
   "metadata": {},
   "source": [
    "__ANSWER__: c) `0.90`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e964b9",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "- 0.11\n",
    "- 0.66\n",
    "- 0.99\n",
    "- 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.stdev(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246acc4",
   "metadata": {},
   "source": [
    "__ANSWER__: a) `0.11`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f520e0f",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "For the next two questions, we'll generate more data using data augmentations.\n",
    "\n",
    "\n",
    "Add the following augmentations to your training data generator:\n",
    "\n",
    "- `rotation_range=40,`\n",
    "\n",
    "\n",
    "- `width_shift_range=0.2,`\n",
    "\n",
    "\n",
    "- `height_shift_range=0.2,`\n",
    "\n",
    "\n",
    "- `shear_range=0.2,`\n",
    "\n",
    "\n",
    "- `zoom_range=0.2,`\n",
    "\n",
    "\n",
    "- `horizontal_flip=True,`\n",
    "\n",
    "\n",
    "- `fill_mode='nearest'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2210a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             rotation_range=40,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "train_generator = datagen.flow_from_directory(TRAIN_DIR, class_mode=\"binary\",target_size=(150,150))\n",
    "validation_generator = datagen.flow_from_directory(TEST_DIR, class_mode=\"binary\",target_size=(150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eabebfe",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously. Make sure you don't re-create the model - we want to continue training the model we already started training.\n",
    "\n",
    "What is the mean of validation loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "- 0.15\n",
    "- 0.77\n",
    "- 0.37\n",
    "- 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2=model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be774d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.mean(history.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7bb665",
   "metadata": {},
   "source": [
    "__ANSWER__: c) `0.37`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d6bf9f",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "What's the average of validation accuracy for the last 5 epochs (from 6 to 10) for the model trained with augmentations?\n",
    "\n",
    "- 0.84\n",
    "- 0.54\n",
    "- 0.44\n",
    "- 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfabe9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.mean(history.history[\"val_accuracy\"][5:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e204595",
   "metadata": {},
   "source": [
    "__ANSWER__: a) `0.84`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
