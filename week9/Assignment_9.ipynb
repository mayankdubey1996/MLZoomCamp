{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf5831a1",
   "metadata": {},
   "source": [
    "In this homework, we'll deploy the dino or dragon model we trained in the previous homework.\n",
    "\n",
    "Download the model from here:\n",
    "\n",
    "https://github.com/SVizor42/ML_Zoomcamp/releases/download/dino-dragon-model/dino_dragon_10_0.899.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd73ad37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "\n",
    "import tensorflow.lite as tflite\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c09b96",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Now convert this model from Keras to TF-Lite format.\n",
    "\n",
    "What's the size of the __converted__ model?\n",
    "\n",
    "- 21 Mb\n",
    "- 43 Mb\n",
    "- 80 Mb\n",
    "- 164 Mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a788b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('dino_dragon_10_0.899.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ab1d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mayan\\AppData\\Local\\Temp\\tmpb5111nnv\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\mayan\\AppData\\Local\\Temp\\tmpb5111nnv\\assets\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('dino_dragon_10_0.899.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f958a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44866124"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get file size in bytes for a given model\n",
    "os.stat('dino_dragon_10_0.899.tflite').st_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0590c5b",
   "metadata": {},
   "source": [
    "__ANSWER__ : __b__ `43 Mb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62913a29",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "To be able to use this model, we need to know the index of the input and the index of the output.\n",
    "\n",
    "What's the output index for this model?\n",
    "\n",
    "- 3\n",
    "- 7\n",
    "- 13\n",
    "- 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d4da62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tflite.Interpreter(model_path='dino_dragon_10_0.899.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "output_idx = interpreter.get_output_details()[0]['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d52a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87076dff",
   "metadata": {},
   "source": [
    "__ANSWER__ : __c__ `13 Mb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca5bb0",
   "metadata": {},
   "source": [
    "### Preparing the image\n",
    "You'll need some code for downloading and resizing images. You can use this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce3044da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from urllib import request\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815955ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45a33e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/df/Smaug_par_David_Demaret.jpg/1280px-Smaug_par_David_Demaret.jpg\"\n",
    "img = download_image(url)\n",
    "img = prepare_image(img, target_size=(150,150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8ab6b6",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Now we need to turn the image into numpy array and pre-process it.\n",
    "\n",
    "Tip: Check the previous homework. What was the pre-processing we did there?\n",
    "\n",
    "After the pre-processing, what's the value in the first pixel, the R channel?\n",
    "\n",
    "- 0.3353411\n",
    "- 0.5529412\n",
    "- 0.7458824\n",
    "- 0.9654902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "290a4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(x):\n",
    "    return x / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95cce7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00041522513"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(img, dtype='float32')\n",
    "X = preprocess_input(x)\n",
    "X = np.array([X])\n",
    "X = prepare_input(X)\n",
    "X[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5222a092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150, 150, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3eb4f",
   "metadata": {},
   "source": [
    "__ANSWER__ : __b__ `0.5529412`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e0e6b4",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "Now let's apply this model to this image. What's the output of the model?\n",
    "\n",
    "- 0.17049132\n",
    "- 0.39009996\n",
    "- 0.60146114\n",
    "- 0.82448614"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b676939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22139649]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_idx = interpreter.get_input_details()[0]['index']\n",
    "interpreter.set_tensor(input_idx, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_idx)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cb3377",
   "metadata": {},
   "source": [
    "__ANSWER__ : __d__ `0.82448614`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42709b04",
   "metadata": {},
   "source": [
    "### Docker\n",
    "For the next two questions, we'll use a Docker image that we already prepared. This is the Dockerfile that we used for creating the image:\n",
    "\n",
    "FROM public.ecr.aws/lambda/python:3.9\n",
    "COPY dino-vs-dragon-v2.tflite .\n",
    "And pushed it to svizor42/zoomcamp-dino-dragon-lambda:v2.\n",
    "\n",
    "A few notes:\n",
    "\n",
    "The image already contains a model and it's not the same model as the one we used for questions 1-4.\n",
    "The version of Python is 3.9, so you need to use the right wheel for TF-Lite. For Tensorflow 2.7.0, it's https://github.com/alexeygrigorev/tflite-aws-lambda/raw/main/tflite/tflite_runtime-2.7.0-cp39-cp39-linux_x86_64.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb99443",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "Download the base image svizor42/zoomcamp-dino-dragon-lambda:v2. You can easily make it by using docker pull command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "- 139 Mb\n",
    "- 329 Mb\n",
    "- 639 Mb\n",
    "- 929 Mb\n",
    "\n",
    "You can get this information when running docker images - it'll be in the \"SIZE\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "800e5b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                             TAG           IMAGE ID       CREATED       SIZE\n",
      "svizor42/zoomcamp-dino-dragon-lambda   v2            20ef58b21a05   11 days ago   639MB\n",
      "app                                    latest        867c1c61a59c   3 weeks ago   1.71GB\n",
      "mlapp                                  latest        28c771ba5243   3 weeks ago   1.67GB\n",
      "flights                                latest        1f8db05c37a2   3 weeks ago   1.88GB\n",
      "<none>                                 <none>        b27ab44823bf   3 weeks ago   1.88GB\n",
      "<none>                                 <none>        423442317309   3 weeks ago   1.88GB\n",
      "docker_tutorial                        latest        fd0f462016a3   3 weeks ago   250MB\n",
      "<none>                                 <none>        7111a8626832   3 weeks ago   211MB\n",
      "hello                                  latest        ce89620bd7ea   7 weeks ago   585MB\n",
      "<none>                                 <none>        ff0d39b77581   7 weeks ago   585MB\n",
      "<none>                                 <none>        a621b240cc5c   7 weeks ago   585MB\n",
      "<none>                                 <none>        fc36f7963293   7 weeks ago   585MB\n",
      "<none>                                 <none>        811f37d503e7   7 weeks ago   585MB\n",
      "<none>                                 <none>        98b08e5a35f5   7 weeks ago   585MB\n",
      "<none>                                 <none>        cd0b9b8e2cfc   7 weeks ago   585MB\n",
      "<none>                                 <none>        00484364e19e   7 weeks ago   581MB\n",
      "<none>                                 <none>        08cacfe05316   7 weeks ago   174MB\n",
      "svizor/zoomcamp-model                  3.9.12-slim   571a6fdc554b   8 weeks ago   125MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeaaa13",
   "metadata": {},
   "source": [
    "__ANSWER__ : __c__ `639MB`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2eefe20",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Now let's extend this docker image, install all the required libraries and add the code for lambda.\n",
    "\n",
    "You don't need to include the model in the image. It's already included. The name of the file with the model is dino-vs-dragon-v2.tflite and it's in the current workdir in the image (see the Dockerfile above for the reference).\n",
    "\n",
    "Now run the container locally.\n",
    "\n",
    "Score this image: https://upload.wikimedia.org/wikipedia/en/e/e9/GodzillaEncounterModel.jpg\n",
    "\n",
    "What's the output from the model?\n",
    "\n",
    "- 0.12\n",
    "- 0.32\n",
    "- 0.52\n",
    "- 0.72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d27cc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3495881]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://upload.wikimedia.org/wikipedia/en/e/e9/GodzillaEncounterModel.jpg\"\n",
    "img = download_image(url)\n",
    "img = prepare_image(img, target_size=(150,150))\n",
    "\n",
    "x = np.array(img, dtype='float32')\n",
    "X = preprocess_input(X)\n",
    "X = np.array([x])\n",
    "X = prepare_input(X)\n",
    "\n",
    "interpreter.set_tensor(input_idx, X)\n",
    "interpreter.invoke()\n",
    "preds = interpreter.get_tensor(output_idx)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f88930",
   "metadata": {},
   "source": [
    "__ANSWER__ : __b__ `0.32`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa55736d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
